# ğŸ¯ Cortex-ARC Vision

> One Model. All Abilities. Any Domain.

---

## The Core Insight

**The brain is not modular in the way software is modular.**

Brain "regions" are not separate programs. They're densely interconnected parts of ONE neural network. Abilities don't live in isolated modules â€” they EMERGE from the unified learning of the whole system.

Our model follows this principle:

```
NOT:  ColorModule + SpatialModule + PatternModule â†’ Stitch together
YES:  ONE model â†’ Train on diverse tasks â†’ All abilities emerge
```

---

## What We're Building

### A Unified Reasoning Core

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                  â”‚
â”‚                    ONE SET OF WEIGHTS                            â”‚
â”‚                                                                  â”‚
â”‚   Learns through training:                                       â”‚
â”‚                                                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚   â”‚  Color  â”‚  â”‚ Spatial â”‚  â”‚ Pattern â”‚  â”‚ Objects â”‚            â”‚
â”‚   â”‚ Ability â”‚  â”‚ Ability â”‚  â”‚ Ability â”‚  â”‚ Ability â”‚            â”‚
â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜            â”‚
â”‚        â”‚            â”‚            â”‚            â”‚                  â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                         â”‚                                        â”‚
â”‚                         â–¼                                        â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚
â”‚              â”‚  Relations Ability  â”‚                             â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
â”‚                         â”‚                                        â”‚
â”‚                         â–¼                                        â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚
â”‚              â”‚  Reasoning Ability  â”‚                             â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
â”‚                                                                  â”‚
â”‚   All abilities are EMERGENT from the same weights.              â”‚
â”‚   Not separate models. Not stitched together.                    â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## How Abilities Emerge

### Brain Analogy

```
Human brain:
  - ~86 billion neurons
  - ONE connected network
  - Different regions specialize through DEVELOPMENT and LEARNING
  - V4 "specializes" in color because it receives that input
  - Parietal "specializes" in space because of its connectivity
  - BUT they're all part of the SAME network
```

### Our Model

```
Cortex model:
  - ~10M parameters (small, efficient)
  - ONE connected network
  - Different abilities emerge through TRAINING
  - Color ability emerges from color-relevant patterns in data
  - Spatial ability emerges from position-relevant patterns
  - BUT they're all in the SAME weights
```

---

## Training Philosophy

### Not Curriculum of Separate Skills

```
âŒ WRONG:
  1. Train Color Model
  2. Train Spatial Model
  3. Train Pattern Model
  4. Somehow combine them
```

### Unified Learning

```
âœ… RIGHT:
  1. Train ONE model on ALL tasks
  2. Tasks naturally require multiple abilities
  3. Model learns to compose abilities automatically
  4. Abilities share representations
```

### Example: Learning from ARC

```
ARC Task: "Move the blue object right"

To solve, model must:
  â€¢ Understand "blue" (color ability)
  â€¢ Understand "object" (segmentation ability)
  â€¢ Understand "right" (spatial ability)
  â€¢ Understand "move" (transformation ability)

These abilities develop TOGETHER, not separately.
```

---

## Multi-Domain Generalization

### The Key: Preprocessing

```
Domain â†’ Preprocessor â†’ Grid â†’ Model â†’ Output

The MODEL is domain-agnostic.
Only PREPROCESSING is domain-specific.
```

### Examples

**Chess:**
```python
def chess_to_grid(board):
    # Convert 8x8 board to grid
    # Pieces become colors 1-6
    # Empty = 0
    return grid

# Training: (board_before, board_after) pairs
# Model learns piece movements
```

**Sudoku:**
```python
def sudoku_to_grid(puzzle):
    # 9x9 grid, numbers 0-9
    # Empty cells = 0
    return grid

# Training: (incomplete, complete) pairs
# Model learns constraint satisfaction
```

**Any New Game:**
```python
def new_game_to_grid(state):
    # Convert game state to grid
    return grid

# Just write the preprocessor!
# Model's abilities transfer
```

---

## Why One Model Works

### Shared Representations

```
"Blue object in top-left"

Color representation: [blue]
Spatial representation: [top-left]
Object representation: [contiguous region]

These representations are SHARED across all tasks.
Learning one task helps all other tasks.
```

### Compositionality

```
Task A: Learn "blue"
Task B: Learn "top-left"
Task C: Learn "move"

New Task: "Move blue object from top-left to bottom-right"
  â†’ Compose existing abilities
  â†’ No retraining needed
```

### Efficiency

```
Separate models:
  ColorModel: 5M params
  SpatialModel: 5M params
  PatternModel: 5M params
  ObjectModel: 5M params
  TOTAL: 20M params + communication overhead

Unified model:
  CortexModel: 10M params
  TOTAL: 10M params, naturally integrated
```

---

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        CORTEX MODEL                              â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ INPUT ENCODING                                              â”‚ â”‚
â”‚  â”‚   Grid â†’ Learned embeddings                                 â”‚ â”‚
â”‚  â”‚   Position encoding                                         â”‚ â”‚
â”‚  â”‚   Color encoding (learned, not hardcoded)                   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                              â”‚                                   â”‚
â”‚                              â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ REASONING CORE                                              â”‚ â”‚
â”‚  â”‚   Transformer/Attention layers                              â”‚ â”‚
â”‚  â”‚   Learns all abilities in shared weights                    â”‚ â”‚
â”‚  â”‚   Recursive: Can refine answer over multiple passes         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                              â”‚                                   â”‚
â”‚                              â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ OUTPUT DECODING                                             â”‚ â”‚
â”‚  â”‚   Embeddings â†’ Grid                                         â”‚ â”‚
â”‚  â”‚   Autoregressive or direct prediction                       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Comparison

| Aspect | Modular (Separate) | Unified (Ours) |
|--------|-------------------|----------------|
| Architecture | Multiple models | One model |
| Communication | Explicit, complex | Implicit, natural |
| Training | Separate, then combine | End-to-end |
| Representations | Separate per module | Shared |
| Compositionality | Hard | Natural |
| Proven | âŒ No winner | âœ… TRM shows it works |

---

## Roadmap

### Phase 1: Core Model
- Design unified architecture
- Implement training loop
- Train on ARC-AGI
- Validate: 40%+ ARC-AGI-1

### Phase 2: Multi-Domain
- Chess, Sudoku, Minesweeper preprocessors
- Validate transfer learning
- Fine-tune if needed

### Phase 3: Multi-Modal
- Image encoder â†’ Unified space
- Text encoder â†’ Unified space
- Same reasoning core

---

## Success Criteria

```
1. ONE model handles ALL ARC tasks
2. Same model transfers to Chess/Sudoku via preprocessing
3. Abilities compose (novel combinations work)
4. Generalizes to ARC-AGI-2 (never seen during training)
```

---

## Summary

We're not building a committee of experts.
We're not stitching modules together.
We're building ONE brain that learns to reason.

Different abilities emerge naturally from unified training.
That's how real brains work.
That's how our model works.
