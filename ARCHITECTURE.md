# Project Architecture

## Overview
This document outlines the technical architecture for the ARC-AGI curriculum learning system.

## Design Principles

1. **Modularity**: Each curriculum skill is a separate, testable module
2. **Composability**: Skills can be combined to solve complex tasks
3. **Interpretability**: Clear reasoning traces showing which skills are applied
4. **Scalability**: Easy to add new skills to the curriculum
5. **Measurability**: Each skill has quantifiable success metrics

---

## System Architecture

```
arc-agi-solver/
â”‚
â”œâ”€â”€ data/                          # ARC dataset
â”‚   â”œâ”€â”€ training/                  # 400 training tasks
â”‚   â”œâ”€â”€ evaluation/                # 400 evaluation tasks  
â”‚   â””â”€â”€ curriculum/                # Synthetic curriculum tasks
â”‚       â”œâ”€â”€ object_cognition/
â”‚       â”œâ”€â”€ numerosity/
â”‚       â”œâ”€â”€ geometry/
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/                      # Core knowledge priors
â”‚   â”‚   â”œâ”€â”€ object_cognition.py
â”‚   â”‚   â”œâ”€â”€ numerosity.py
â”‚   â”‚   â”œâ”€â”€ geometry.py
â”‚   â”‚   â”œâ”€â”€ topology.py
â”‚   â”‚   â””â”€â”€ physics.py
â”‚   â”‚
â”‚   â”œâ”€â”€ operations/                # Cognitive operations
â”‚   â”‚   â”œâ”€â”€ pattern_recognition.py
â”‚   â”‚   â”œâ”€â”€ transformation.py
â”‚   â”‚   â”œâ”€â”€ analogy.py
â”‚   â”‚   â”œâ”€â”€ goal_reasoning.py
â”‚   â”‚   â””â”€â”€ hypothesis_testing.py
â”‚   â”‚
â”‚   â”œâ”€â”€ meta/                      # Meta-cognitive skills
â”‚   â”‚   â”œâ”€â”€ attention.py
â”‚   â”‚   â”œâ”€â”€ working_memory.py
â”‚   â”‚   â””â”€â”€ search.py
â”‚   â”‚
â”‚   â”œâ”€â”€ curriculum/                # Curriculum training
â”‚   â”‚   â”œâ”€â”€ task_generator.py     # Generate synthetic tasks
â”‚   â”‚   â”œâ”€â”€ trainer.py             # Training loop
â”‚   â”‚   â”œâ”€â”€ scheduler.py           # Curriculum scheduling
â”‚   â”‚   â””â”€â”€ evaluator.py           # Skill assessment
â”‚   â”‚
â”‚   â”œâ”€â”€ model/                     # Neural architecture
â”‚   â”‚   â”œâ”€â”€ encoder.py             # Grid encoder
â”‚   â”‚   â”œâ”€â”€ reasoning.py           # Reasoning module
â”‚   â”‚   â”œâ”€â”€ decoder.py             # Grid decoder
â”‚   â”‚   â””â”€â”€ skill_modules.py       # Skill-specific modules
â”‚   â”‚
â”‚   â”œâ”€â”€ solver/                    # Task solver
â”‚   â”‚   â”œâ”€â”€ arc_solver.py          # Main solver
â”‚   â”‚   â”œâ”€â”€ skill_composer.py      # Combine skills
â”‚   â”‚   â””â”€â”€ search_strategy.py     # Solution search
â”‚   â”‚
â”‚   â””â”€â”€ utils/                     # Utilities
â”‚       â”œâ”€â”€ grid_utils.py          # Grid operations
â”‚       â”œâ”€â”€ visualization.py       # Visualize tasks/solutions
â”‚       â””â”€â”€ metrics.py             # Evaluation metrics
â”‚
â”œâ”€â”€ tests/                         # Unit tests
â”‚   â”œâ”€â”€ test_core/
â”‚   â”œâ”€â”€ test_operations/
â”‚   â”œâ”€â”€ test_meta/
â”‚   â””â”€â”€ test_curriculum/
â”‚
â”œâ”€â”€ configs/                       # Configuration files
â”‚   â”œâ”€â”€ curriculum.yaml            # Curriculum schedule
â”‚   â”œâ”€â”€ model.yaml                 # Model architecture
â”‚   â””â”€â”€ training.yaml              # Training hyperparameters
â”‚
â”œâ”€â”€ scripts/                       # Utility scripts
â”‚   â”œâ”€â”€ download_dataset.py        # âœ… Download ARC data
â”‚   â”œâ”€â”€ analyze_tasks.py           # âœ… Analyze task skills
â”‚   â”œâ”€â”€ generate_curriculum.py     # Generate curriculum tasks
â”‚   â”œâ”€â”€ train.py                   # Training script
â”‚   â””â”€â”€ evaluate.py                # Evaluation script
â”‚
â”œâ”€â”€ notebooks/                     # Jupyter notebooks
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_skill_development.ipynb
â”‚   â””â”€â”€ 03_curriculum_analysis.ipynb
â”‚
â”œâ”€â”€ CURRICULUM.md                  # âœ… Curriculum design
â”œâ”€â”€ README.md                      # âœ… Project overview
â””â”€â”€ requirements.txt               # Python dependencies
```

---

## Core Components

### 1. Skill Modules

Each skill is implemented as a separate module with a standard interface:

```python
class SkillModule:
    def forward(self, grid: Grid, context: Context) -> SkillOutput:
        """Apply skill to grid."""
        pass
    
    def train(self, task: Task) -> Loss:
        """Train on curriculum task."""
        pass
    
    def evaluate(self, task: Task) -> Metrics:
        """Evaluate skill performance."""
        pass
```

### 2. Task Generator

Generates synthetic tasks for each curriculum skill:

```python
class TaskGenerator:
    def generate_object_cognition_tasks(n: int) -> List[Task]:
        """Generate tasks requiring object cognition."""
        pass
    
    def generate_geometry_tasks(n: int) -> List[Task]:
        """Generate tasks requiring geometric reasoning."""
        pass
    
    # ... one generator per skill ...
```

### 3. Curriculum Scheduler

Manages progression through curriculum:

```python
class CurriculumScheduler:
    def get_current_stage(self) -> Stage:
        """Return current curriculum stage."""
        pass
    
    def get_next_batch(self) -> Batch:
        """Sample tasks for current stage."""
        pass
    
    def should_advance(self, metrics: Metrics) -> bool:
        """Check if ready to advance to next stage."""
        pass
```

### 4. Skill Composer

Combines skills to solve complex tasks:

```python
class SkillComposer:
    def decompose_task(self, task: Task) -> List[Skill]:
        """Identify which skills are needed."""
        pass
    
    def compose_solution(self, skills: List[Skill], task: Task) -> Solution:
        """Combine skills to solve task."""
        pass
```

### 5. ARC Solver

Main solver that uses skills to solve ARC tasks:

```python
class ARCSolver:
    def solve(self, task: ARCTask) -> Solution:
        """
        1. Analyze task to identify required skills
        2. Compose skills into a solution strategy
        3. Execute strategy to produce output
        4. Verify solution against test cases
        """
        pass
```

---

## Model Architecture

### Grid Encoder
- Input: 2D grid (up to 30x30, 10 colors)
- Output: Latent representation capturing spatial structure

### Reasoning Module  
- Multiple skill-specific sub-modules
- Attention mechanism to select relevant skills
- Compositional reasoning (combine skills)

### Grid Decoder
- Input: Latent representation + goal specification
- Output: Predicted output grid

---

## Training Strategy

### Phase 1: Individual Skill Training
- Train each skill module independently
- Use skill-specific curriculum tasks
- Achieve >90% accuracy on each skill before advancing

### Phase 2: Skill Composition
- Train on tasks requiring 2-3 skills
- Learn to chain/combine operations
- Develop skill selection strategy

### Phase 3: Complex Reasoning
- Train on tasks requiring 3+ skills
- Learn meta-reasoning (when to use which skill)
- Develop search and planning

### Phase 4: ARC Transfer
- Evaluate on ARC training set
- Fine-tune skill composition
- Optimize for ARC-specific patterns

### Phase 5: Final Evaluation
- Test on held-out ARC evaluation set
- Measure generalization performance
- Analyze failure modes

---

## Evaluation Metrics

### Skill-Level Metrics
- **Accuracy**: % of curriculum tasks solved correctly
- **Generalization**: Performance on novel variations
- **Efficiency**: Computational cost per task
- **Robustness**: Performance under noise/perturbations

### Task-Level Metrics
- **Solve Rate**: % of ARC tasks solved
- **Attempt Efficiency**: Average attempts needed
- **Skill Coverage**: Which skills are actually used
- **Error Analysis**: Why failures occur

### Meta-Level Metrics
- **Data Efficiency**: Performance vs. training examples
- **Transfer**: Curriculum â†’ ARC performance gap
- **Interpretability**: Clarity of reasoning traces
- **Novelty Handling**: Performance on unusual tasks

---

## Technology Stack

### Core
- **Python 3.10+**: Main language
- **PyTorch 2.0+**: Deep learning framework
- **NumPy**: Grid operations

### Training
- **PyTorch Lightning**: Training infrastructure
- **WandB**: Experiment tracking
- **Hydra**: Configuration management

### Utilities
- **Matplotlib/Seaborn**: Visualization
- **Pandas**: Data analysis
- **Pytest**: Testing

---

## Development Roadmap

### Week 1-2: Foundation âœ…
- [x] Define curriculum (CURRICULUM.md)
- [x] Download ARC dataset
- [x] Analyze task skill requirements
- [ ] Set up project structure
- [ ] Implement grid utilities

### Week 3-4: Core Skills
- [ ] Implement object cognition module
- [ ] Implement numerosity module
- [ ] Implement geometry module
- [ ] Generate curriculum tasks for core skills
- [ ] Train and evaluate core skills

### Week 5-6: Cognitive Operations
- [ ] Implement pattern recognition
- [ ] Implement transformations
- [ ] Implement analogy reasoning
- [ ] Generate curriculum tasks
- [ ] Train and evaluate

### Week 7-8: Skill Composition
- [ ] Implement skill composer
- [ ] Generate multi-skill tasks
- [ ] Train composition system
- [ ] Evaluate on complex curriculum tasks

### Week 9-10: ARC Integration
- [ ] Integrate with ARC tasks
- [ ] Implement full solver pipeline
- [ ] Tune and optimize
- [ ] Final evaluation on ARC eval set

---

## Success Criteria

**Minimum Viable Performance**:
- Each skill module: >85% on curriculum tasks
- Skill composition: >70% on 2-skill tasks
- ARC training set: >30% solve rate

**Target Performance**:
- Each skill module: >95% on curriculum tasks
- Skill composition: >85% on 3-skill tasks  
- ARC training set: >50% solve rate
- ARC eval set: >40% solve rate

**Stretch Goal**:
- ARC eval set: >60% solve rate (human-level)

---

## Next Steps

1. **Verify dataset download** - Ensure all 800 tasks downloaded
2. **Run task analysis** - Validate curriculum against real ARC tasks
3. **Build project structure** - Create directories and base classes
4. **Implement grid utilities** - Core operations for grid manipulation
5. **Start with object cognition** - First curriculum module

The foundation is ready. Now we build! ðŸš€
